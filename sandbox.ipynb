{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "from process_data import save_pickle, load_pickle, load_task, load_glove_weights\n",
    "from process_data import to_var, make_word_vector, make_char_vector\n",
    "from layers.char_embedding import CharEmbedding\n",
    "from layers.word_embedding import WordEmbedding\n",
    "from layers.highway import Highway\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset version: 1.1\n",
      "load_task: 0 / 442\n",
      "load_task: 100 / 442\n",
      "load_task: 200 / 442\n",
      "load_task: 300 / 442\n",
      "load_task: 400 / 442\n",
      "dataset version: 1.1\n",
      "load_task: 0 / 48\n",
      "----\n",
      "n_train 61319\n",
      "ctx_maxlen 4063\n",
      "vocab_size_w: 146367\n",
      "vocab_size_c: 1176\n",
      "ctx_sent_maxlen: 766\n",
      "query_sent_maxlen: 60\n",
      "ctx_word_maxlen: 36\n",
      "query_word_maxlen: 26\n"
     ]
    }
   ],
   "source": [
    "train_data, train_ctx_maxlen = load_task('./dataset/train-v1.1.json')\n",
    "train_data = train_data[:int(len(train_data)*0.7)]\n",
    "dev_data, dev_ctx_maxlen = load_task('./dataset/dev-v1.1.json')\n",
    "data = train_data + dev_data\n",
    "ctx_maxlen = max(train_ctx_maxlen, dev_ctx_maxlen)\n",
    "# save_pickle(train_data, 'pickle/train_data.pickle')\n",
    "# save_pickle(dev_data, 'pickle/dev_data.pickle')\n",
    "\n",
    "vocab_w, vocab_c = set(), set()\n",
    "for ctx_w, ctx_c, q_id, q_w, q_c, answer, _, _ in data:\n",
    "    vocab_w |= set(ctx_w + q_w + answer)\n",
    "    flatten_c = [c for chars in ctx_c for c in chars]\n",
    "    flatten_q = [c for chars in q_c for c in chars]\n",
    "\n",
    "    vocab_c |= set(flatten_c + flatten_q) # TODO\n",
    "\n",
    "vocab_w = list(sorted(vocab_w))\n",
    "vocab_c = list(sorted(vocab_c))\n",
    "\n",
    "w2i_w = dict((w, i) for i, w in enumerate(vocab_w, 0))\n",
    "i2w_w = dict((i, w) for i, w in enumerate(vocab_w, 0))\n",
    "w2i_c = dict((c, i) for i, c in enumerate(vocab_c, 0))\n",
    "i2w_c = dict((i, c) for i, c in enumerate(vocab_c, 0))\n",
    "# save_pickle(vocab, 'pickle/vocab.pickle')\n",
    "# save_pickle(w2i, 'pickle/w2i.pickle')\n",
    "# save_pickle(i2w, 'pickle/i2w.pickle')\n",
    "# train_data = load_pickle('pickle/train_data.pickle')\n",
    "# vocab = load_pickle('pickle/vocab.pickle')\n",
    "# w2i = load_pickle('pickle/w2i.pickle')\n",
    "\n",
    "vocab_size_w = len(vocab_w)\n",
    "vocab_size_c = len(vocab_c)\n",
    "\n",
    "ctx_sent_maxlen = max([len(c) for c, _, _, _, _, _, _, _ in data])\n",
    "query_sent_maxlen = max([len(q) for _, _, _, q, _, _, _, _ in data])\n",
    "ctx_word_maxlen = max([len(w) for _, cc, _, _, _, _, _, _ in data for w in cc])\n",
    "query_word_maxlen = max([len(w) for _, _, _, _, qc, _, _, _ in data for w in qc])\n",
    "print('----')\n",
    "print('n_train', len(train_data))\n",
    "# print('n_dev', len(dev_data))\n",
    "print('ctx_maxlen', ctx_maxlen)\n",
    "print('vocab_size_w:', vocab_size_w)\n",
    "print('vocab_size_c:', vocab_size_c)\n",
    "print('ctx_sent_maxlen:', ctx_sent_maxlen)\n",
    "print('query_sent_maxlen:', query_sent_maxlen)\n",
    "print('ctx_word_maxlen:', ctx_word_maxlen)\n",
    "print('query_word_maxlen:', query_word_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "embed_matrix.shape (146367, 100)\n"
     ]
    }
   ],
   "source": [
    "embd_size = 100\n",
    "glove_embd_w = torch.from_numpy(load_glove_weights('./dataset', embd_size, vocab_size_w, w2i_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCTensorMath.cu:35",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9cf7b8daea79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttentionNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;31m# print(model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdadelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device_id)\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0mcopied\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mflatten_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# Allocate buffer to hold the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mnum_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_desc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_descs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_buf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0many_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_weight_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_buf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCTensorMath.cu:35"
     ]
    }
   ],
   "source": [
    "from layers.char_embedding import CharEmbedding\n",
    "from layers.word_embedding import WordEmbedding\n",
    "from layers.highway import Highway\n",
    "\n",
    "args = {\n",
    "    'embd_size': embd_size,\n",
    "    'vocab_size_c': vocab_size_c,\n",
    "    'vocab_size_w': vocab_size_w,\n",
    "    'pre_embd_w': glove_embd_w, # word embedding\n",
    "    'filters': [[1, 5]], # char embedding\n",
    "    'out_chs': 100, # char embedding\n",
    "    'ans_size': ctx_maxlen\n",
    "}\n",
    "args = Config(**args)\n",
    "\n",
    "\n",
    "class AttentionNet(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(AttentionNet, self).__init__()\n",
    "        self.embd_size = args.embd_size\n",
    "        self.ans_size = args.ans_size\n",
    "        self.char_embd_net = CharEmbedding(args)\n",
    "        self.word_embd_net = WordEmbedding(args)\n",
    "        self.highway_net = Highway(args.embd_size*2)# TODO share is ok?\n",
    "        self.ctx_embd_layer = nn.GRU(args.embd_size*2, args.embd_size*2, bidirectional=True)\n",
    "        self.W = nn.Parameter(torch.rand(3*2*2* args.embd_size, 1).type(torch.FloatTensor), requires_grad=True)\n",
    "#         self.beta = nn.Parameter(torch.rand(8*2*2* args.embd_size).type(torch.FloatTensor).view(1, -1), requires_grad=True)\n",
    "        self.modeling_layer = nn.GRU(args.embd_size*2*8, args.embd_size*2, bidirectional=True)\n",
    "        self.p1_layer = nn.Linear(args.embd_size*2*10, args.ans_size)\n",
    "        self.p2_lstm_layer = nn.GRU(args.embd_size*2*2, args.embd_size*2*2, bidirectional=True)\n",
    "        self.p2_layer = nn.Linear(args.embd_size*2*12, args.ans_size)\n",
    "        \n",
    "    def build_contextual_embd(self, x_c, x_w):\n",
    "        # 1. Caracter Embedding Layer\n",
    "        char_embd = self.char_embd_net(x_c) # (N, seq_len, embd_size)\n",
    "        if torch.cuda.is_available():\n",
    "            char_embd = char_embd.cuda()\n",
    "        # 2. Word Embedding Layer\n",
    "        word_embd = self.word_embd_net(x_w) # (N, seq_len, embd_size)\n",
    "        if torch.cuda.is_available():\n",
    "            word_embd = word_embd.cuda()\n",
    "        # Highway Networks of 1. and 2.\n",
    "        embd = torch.cat((char_embd, word_embd), 2) # (N, seq_len, embd_size*2)\n",
    "        embd = self.highway_net(embd)\n",
    "        \n",
    "        # 3. Contextual  Embedding Layer\n",
    "        ctx_embd_out, ctx_embd_h = self.ctx_embd_layer(embd)\n",
    "        return ctx_embd_out\n",
    "        \n",
    "    def forward(self, ctx_c, ctx_w, query_c, query_w):\n",
    "        batch_size = ctx_c.size(0)\n",
    "        \n",
    "        # 1. Caracter Embedding Layer \n",
    "        # 2. Word Embedding Layer\n",
    "        # 3. Contextual  Embedding Layer\n",
    "        embd_context = self.build_contextual_embd(ctx_c, ctx_w) # (N, T, 2d)\n",
    "        ctx_len = embd_context.size(1)\n",
    "        embd_query   = self.build_contextual_embd(query_c, query_w) # (N, J, 2d)\n",
    "        query_len = embd_query.size(1)\n",
    "        \n",
    "        # 4. Attention Flow Layer\n",
    "        # Context2Query\n",
    "        shape = (batch_size, ctx_len, query_len, self.embd_size*2*2) # (N, T, J, 2d)\n",
    "        embd_context_ex = embd_context.unsqueeze(2) # (N, T, 1, 2d)\n",
    "        embd_context_ex = embd_context_ex.expand(shape)\n",
    "        embd_query_ex = embd_query.unsqueeze(1) # (N, 1, J, 2d)\n",
    "        embd_query_ex = embd_query_ex.expand(shape)\n",
    "        a_elmwise_mul_b = torch.mul(embd_context_ex, embd_query_ex) # (N, T, J, 2d)\n",
    "        cat_data = torch.cat((embd_context_ex, embd_query_ex, a_elmwise_mul_b), 3) # (N, T, J, 6d)\n",
    "        cat_data = cat_data.view(batch_size, -1, 6*2*self.embd_size)\n",
    "        S = torch.bmm(cat_data, self.W.unsqueeze(0).expand(batch_size, 6*2*self.embd_size, 1))\n",
    "        S = S.view(batch_size, ctx_len, query_len)\n",
    "        \n",
    "        c2q = torch.bmm(S, embd_query) # (N, T, 2d)\n",
    "        # Query2Context\n",
    "        tmp_b = torch.max(S, 2)[0]\n",
    "        b = torch.stack([F.softmax(tmp_b[i]) for i in range(batch_size)], 0) # (N, T)\n",
    "        q2c = torch.bmm(b.unsqueeze(1), embd_context).squeeze() # (N, 2d)\n",
    "        q2c = q2c.unsqueeze(1) # (N, 1, 2d)\n",
    "        q2c = q2c.repeat(1, ctx_len, 1) # (N, T, 2d)\n",
    "        \n",
    "        G = torch.cat((embd_context, c2q, embd_context.mul(c2q), embd_context.mul(q2c)), 2) # (N, T, 8d)\n",
    "        \n",
    "        # 5. Modeling Layer\n",
    "        M, _ = self.modeling_layer(G) # M: (N, T, 2d)\n",
    "        \n",
    "        # 5. Output Layer\n",
    "        G_M = torch.cat((G, M), 2) # (N, T, 10d)\n",
    "        G_M = G_M.sum(1) #(N, 10d)\n",
    "        p1 = F.softmax(self.p1_layer(G_M)) # (N, T)\n",
    "        \n",
    "        M2, _ = self.p2_lstm_layer(M) # (N, T, 4d)\n",
    "        G_M2 = torch.cat((G, M2), 2) # (N, T, 12d)\n",
    "        G_M2 = G_M2.sum(1) # (N, 12d)(N, T)\n",
    "        p2 = F.softmax(self.p2_layer(G_M2)) # (N, T)\n",
    "        \n",
    "        return p1, p2\n",
    "        \n",
    "def train(model, optimizer, n_epoch=10, batch_size=1):\n",
    "    for epoch in range(n_epoch):\n",
    "        for i in range(0, len(data)-batch_size, batch_size): # TODO shuffle, last elms\n",
    "            print('batch', i, '/', len(data))\n",
    "            batch_data = data[i:i+batch_size]\n",
    "            c = [d[0] for d in batch_data]\n",
    "            cc = [d[1] for d in batch_data]\n",
    "            q = [d[3] for d in batch_data]\n",
    "            qc = [d[4] for d in batch_data]\n",
    "            a_beg = to_var(torch.LongTensor([d[6] for d in batch_data]).squeeze())\n",
    "            a_end = to_var(torch.LongTensor([d[7] for d in batch_data]).squeeze())\n",
    "            c_char_var = make_char_vector(cc, w2i_c, ctx_sent_maxlen, ctx_word_maxlen)\n",
    "            c_word_var = make_word_vector(c, w2i_w, ctx_sent_maxlen)\n",
    "            q_char_var = make_char_vector(qc, w2i_c, query_sent_maxlen, query_word_maxlen)\n",
    "            q_word_var = make_word_vector(q, w2i_w, query_sent_maxlen)\n",
    "            p1, p2 = model(c_char_var, c_word_var, q_char_var, q_word_var)\n",
    "            loss_p1 = nn.NLLLoss()(p1, a_beg)\n",
    "            loss_p2 = nn.NLLLoss()(p2, a_end)\n",
    "            model.zero_grad()\n",
    "#             print('loss.backward()')\n",
    "            (loss_p1+loss_p2).backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "#             break\n",
    "model = AttentionNet(args)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "# print(model)\n",
    "optimizer = torch.optim.Adadelta(filter(lambda p: p.requires_grad, model.parameters()), lr=0.5)\n",
    "train(model, optimizer)\n",
    "print('finish train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 16\n",
    "hid_dim = 50\n",
    "a_seq_len = 10\n",
    "b_seq_len = 20\n",
    "a = torch.randn(N, a_seq_len, hid_dim)\n",
    "b = torch.randn(N, b_seq_len, hid_dim)\n",
    "shape = (N, a_seq_len, b_seq_len, hid_dim)\n",
    "\n",
    "result = torch.zeros(shape)\n",
    "\n",
    "a_dash = a.unsqueeze(2) # (N, a_len, 1,     hid_dim)\n",
    "b_dash = b.unsqueeze(1) # (N, 1,     b_len, hid_dim)\n",
    "a_dash = a_dash.expand(shape)\n",
    "b_dash = b_dash.expand(shape)\n",
    "mul = a_dash * b_dash\n",
    "\n",
    "print(a_dash.size(), b_dash.size(), mul.size())\n",
    "print(torch.cat((a_dash, b_dash, mul), 3).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "x_len = 3\n",
    "y_len = 5\n",
    "hid_dim = 8\n",
    "data = torch.randn(N, x_len, y_len, hid_dim)\n",
    "W = torch.randn(hid_dim)\n",
    "print(torch.mul(data, W).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hid_dim = 54\n",
    "tdata = torch.Tensor([[\n",
    "    [1] * hid_dim,\n",
    "    [2] * hid_dim,\n",
    "    [3] * hid_dim \n",
    "],\n",
    "[\n",
    "    [1] * hid_dim,\n",
    "    [2] * hid_dim,\n",
    "    [3] * hid_dim \n",
    "]])\n",
    "print('data', tdata.size())\n",
    "tW = torch.randn(hid_dim).view(-1, 1) # assume trainable parameters via nn.Parameter\n",
    "print('W', tW.size())\n",
    "\n",
    "print(tdata.size(), tW.unsqueeze(0).size())\n",
    "print(torch.bmm(tdata, tW.unsqueeze(0)).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hid_dim = 32\n",
    "data = torch.randn(10, 6, hid_dim)\n",
    "# data = tdata.view(10, 2*3, hid_dim)\n",
    "W = torch.randn(hid_dim, 1) # assume trainable parameters via nn.Parameter\n",
    "print(W.size())\n",
    "W = W.unsqueeze(0).expand(10, hid_dim, 1)\n",
    "print(W.size())\n",
    "result = torch.bmm(data, W).squeeze() # error, want (N, 6)\n",
    "print(result.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hid_dim = 32\n",
    "data = torch.randn(10, 2, 3, hid_dim)\n",
    "data = tdata.view(10, 2*3, hid_dim)\n",
    "W = torch.randn(hid_dim, 1) # assume trainable parameters via nn.Parameter\n",
    "print(W.size())\n",
    "W = W.unsqueeze(0).expand(10, hid_dim, 1)\n",
    "print(W.size())\n",
    "result = torch.bmm(data, W).squeeze() # error, want (N, 6)\n",
    "result = result.view(10, 2, 3)\n",
    "print(result.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
