{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "from process_data import save_pickle, load_pickle, load_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset version: 1.1\n",
      "load_task: 0 / 442\n",
      "load_task: 100 / 442\n",
      "load_task: 200 / 442\n",
      "load_task: 300 / 442\n",
      "load_task: 400 / 442\n",
      "dataset version: 1.1\n",
      "load_task: 0 / 48\n",
      "save pickle to pickle/train_data.pickle\n",
      "save pickle to pickle/dev_data.pickle\n",
      "save pickle to pickle/vocab.pickle\n",
      "save pickle to pickle/w2i.pickle\n",
      "save pickle to pickle/i2w.pickle\n",
      "load pickle/train_data.pickle\n",
      "load pickle/vocab.pickle\n",
      "load pickle/w2i.pickle\n",
      "vocab size: 186069\n",
      "embd size: 128\n",
      "context_maxlen: 766\n",
      "question_maxlen: 60\n"
     ]
    }
   ],
   "source": [
    "train_data = load_task('./dataset/train-v1.1.json')\n",
    "dev_data = load_task('./dataset/dev-v1.1.json')\n",
    "save_pickle(train_data, 'pickle/train_data.pickle')\n",
    "save_pickle(dev_data, 'pickle/dev_data.pickle')\n",
    "\n",
    "vocab = set()\n",
    "for context, _, q, answer in train_data+dev_data:\n",
    "    vocab |= set(context + q + answer)\n",
    "vocab = list(sorted(vocab))\n",
    "w2i = dict((c, i) for i, c in enumerate(vocab, 0))\n",
    "i2w = dict((i, c) for i, c in enumerate(vocab, 0))\n",
    "save_pickle(vocab, 'pickle/vocab.pickle')\n",
    "save_pickle(w2i, 'pickle/w2i.pickle')\n",
    "save_pickle(i2w, 'pickle/i2w.pickle')\n",
    "train_data = load_pickle('pickle/train_data.pickle')\n",
    "vocab = load_pickle('pickle/vocab.pickle')\n",
    "w2i = load_pickle('pickle/w2i.pickle')\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embd_size = 128\n",
    "context_maxlen = max(map(len, (c for c, _, _, _ in train_data)))\n",
    "question_maxlen = max(map(len, (q for _, _, q, _ in train_data)))\n",
    "print('vocab size:', vocab_size)\n",
    "print('embd size:', embd_size)\n",
    "print('context_maxlen:', context_maxlen)\n",
    "print('question_maxlen:', question_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i', ' ', 'h', 'a', 'v', 'e', ' ', 'a', ' ', 'c', 'a', 't'], ['i', ' ', 'h', 'a', 'd', ' ', 'a', ' ', 'a', 'i', 'e', 'u']]\n",
      "vocab_size 10\n",
      "max_word_len 12\n"
     ]
    }
   ],
   "source": [
    "sent1 = list('i have a cat')\n",
    "sent2 = list('i had a aieu')\n",
    "data = [sent1, sent2]\n",
    "vocab = set(sent1+sent2)\n",
    "vocab_size = len(vocab)\n",
    "print(data)\n",
    "print('vocab_size', vocab_size)\n",
    "w2i = {w:i for i, w in enumerate(vocab)}\n",
    "i2w = {i:w for i, w in enumerate(vocab)}\n",
    "\n",
    "max_word_len = max([len(word) for word in data])\n",
    "print('max_word_len', max_word_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharEmbedding (\n",
      "  (embedding): Embedding(10, 64)\n",
      "  (conv): ModuleList (\n",
      "    (0): Conv2d(1, 100, kernel_size=(1, 5), stride=(1, 1))\n",
      "  )\n",
      "  (dropout): Dropout (p = 0.5)\n",
      "  (fc1): Linear (100 -> 1)\n",
      ")\n",
      "embd torch.Size([1, 12, 64])\n",
      "unsq torch.Size([1, 1, 12, 64])\n",
      "conv[0](x) torch.Size([1, 100, 12, 60])\n",
      "x[0] torch.Size([1, 100, 720])\n",
      "after maxpool torch.Size([1, 100])\n",
      "out torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "class CharEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embd_size, out_chs, filters):\n",
    "        super(CharEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embd_size)\n",
    "        # nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, ...\n",
    "        self.conv = nn.ModuleList([nn.Conv2d(1, out_chs, (f[0], f[1])) for f in filters])\n",
    "        self.dropout = nn.Dropout(.5)\n",
    "        self.fc1 = nn.Linear(out_chs*len(filters), 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.size(0)\n",
    "        x = self.embedding(x) # (N, seq_len, embd_dim)\n",
    "        print('embd', x.size())\n",
    "        x = x.unsqueeze(1) # (N, Cin, W, embd_dim), insert Channnel-In dim\n",
    "        print('unsq', x.size())\n",
    "        print('conv[0](x)', self.conv[0](x).size())\n",
    "        # Conv2d\n",
    "        #    Input : (N,Cin, Hin, Win )\n",
    "        #    Output: (N,Cout,Hout,Wout) \n",
    "        # squeeze(3) means 2D to 1D; (N,Cout,Hout,Wout) -> [(N,Cout,Hout==seq_len)] * len(filter_heights)\n",
    "        x = [F.relu(conv(x)) for conv in self.conv]\n",
    "        x = [xx.view((xx.size(0), xx.size(1), xx.size(2)*xx.size(3))) for xx in x]\n",
    "        print('x[0]', x[0].size())\n",
    "        # max_pool1d(input, kernel_size, ..\n",
    "        # (N, Cout, seq_len) --(max_pool1d)--> (N, Cout, 1) --(squeeze(2))--> (N, Cout)\n",
    "        # [(N, Cout)]  len(filter_heights)\n",
    "        x = [F.max_pool1d(xx, xx.size(2)).squeeze(2) for xx in x]\n",
    "        print('after maxpool', x[0].size())\n",
    "        out = torch.cat(x, 1) # (N, Cout*len(filter_heights))\n",
    "        print('out', out.size())\n",
    "        return out\n",
    "\n",
    "embd_size = 64\n",
    "n_out_ch = 100\n",
    "filters = [[1, 5]]\n",
    "char_embd_net = CharEmbedding(vocab_size, embd_size, n_out_ch, filters)\n",
    "print(char_embd_net)\n",
    "char_var = Variable(torch.LongTensor([[w2i[w] for w in data[0]]]))\n",
    "out = char_embd_net(char_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([1, 2, 3, 4])\n",
    "print(x.size())\n",
    "x.unsqueeze_(0)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
